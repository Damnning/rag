# RAG (Retrieval-Augmented Generation) System

Система поиска и генерации ответов на основе извлечения релевантной информации из документов с использованием векторного поиска и языковых моделей.

## Описание

Этот проект реализует архитектуру RAG для работы с русскоязычными текстами. Система позволяет задавать вопросы и получать ответы на основе анализа локальной коллекции документов, используя семантический поиск и генерацию ответов с помощью языковых моделей.

## Основные возможности

- **Векторный поиск**: Семантический поиск релевантных документов по запросу
- **Поддержка русского языка**: Использует модель `ai-forever/ru-en-RoSBERTa` для создания эмбеддингов
- **Гибкая конфигурация**: Настраиваемые параметры поиска и генерации
- **Кэширование эмбеддингов**: Автоматическое сохранение и переиспользование векторных представлений
- **Интеграция с OpenRouter**: Использование различных языковых моделей через единый API

## Архитектура

### Основные компоненты

1. **DocumentRetriever** - работа с файлами и извлечение текста
2. **DataProcessor** - создание эмбеддингов из текстов
3. **VectorStore** - хранение и поиск по векторам
4. **LLMWrapper** - взаимодействие с языковыми моделями
5. **RAGPipeline** - основная логика RAG системы

### Метрики расстояния

- **Косинусное сходство** (`COS`) - для семантического поиска
- **Скалярное произведение** (`SCALAR`) - альтернативная метрика

## Установка и настройка

### Требования

```bash
pip install -r requirements.txt
```

### Конфигурация

Создайте объект `Config` с необходимыми параметрами:

```python
config = Config(
    root='/path/to/your/documents',  # Путь к папке с документами
    embedding_model='ai-forever/ru-en-RoSBERTa',  # Модель для эмбеддингов
    llm_model='deepseek/deepseek-chat-v3-0324:free',  # Модель для генерации
    api_key='your-openrouter-api-key',  # API ключ OpenRouter
    k=20  # Количество ближайших документов для поиска
)
```

### Структура файлов

```
rag/
├── articles/          # Папка с текстовыми документами
│   ├── doc1.txt
│   ├── doc2.txt
│   └── ...
├── text_vectors.json  # Кэш эмбеддингов (создается автоматически)
└── notebooks/
    └── rag.ipynb      # Jupyter notebook с примером использования
```

## Использование

### Базовый пример

```python
# Инициализация конфигурации
config = Config(
    root='/path/to/documents',
    embedding_model='ai-forever/ru-en-RoSBERTa',
    llm_model='deepseek/deepseek-chat-v3-0324:free',
    api_key='your-api-key',
    k=20
)

# Создание RAG pipeline
pipe = RAGPipeline(config)

# Запрос к системе
query = "Ваш вопрос здесь"
answer = pipe.run(query)
print(answer)
```

### Работа с документами

1. Поместите текстовые файлы в папку `articles/`
2. При первом запуске система автоматически создаст эмбеддинги
3. Последующие запросы будут использовать кэшированные векторы

## API Reference

### Config

```python
class Config:
    def __init__(self, root: str, embedding_model: str, llm_model: str, api_key: str, k: int)
```

**Параметры:**
- `root` - путь к директории с документами
- `embedding_model` - название модели для создания эмбеддингов
- `llm_model` - название модели для генерации ответов
- `api_key` - API ключ для OpenRouter
- `k` - количество ближайших документов для поиска

### RAGPipeline

```python
class RAGPipeline:
    def __init__(self, config: Config)
    def run(self, query: str) -> str
```

**Методы:**
- `run(query)` - выполняет поиск и генерацию ответа для заданного запроса

## Примеры использования

### Поиск информации о подарках

```python
query = "Что можно подарить Ване Транькову на день рождения"
answer = pipe.run(query)
```

Система найдет релевантные документы и сгенерирует ответ на основе найденной информации.

## Технические детали

### Модели

- **Эмбеддинги**: `ai-forever/ru-en-RoSBERTa` - русско-английская модель для создания векторных представлений
- **Генерация**: `deepseek/deepseek-chat-v3-0324:free` - языковая модель для генерации ответов

